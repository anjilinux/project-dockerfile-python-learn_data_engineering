{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining data from NASA LP DAAC - Land Processes Distributed Active Archive Center\n",
    "## Fire boundaries based on the MODIS dataset MCD64A1\n",
    "\n",
    "This notebook demonstrates how to obtain, load, and transform LP DAAC datasets into common and easy to use formats for downstream geospatial data processing and scientific analysis. Here we will obtain the [Terra and Aqua combined Burned Area data product MCD64A1](https://lpdaac.usgs.gov/products/mcd64a1v061/). This data is a monthly, global gridded 500 meter (m) product containing per-pixel burned-area and quality information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from osgeo import gdal\n",
    "import requests\n",
    "import dotenv\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Obtaining data from LP DAAC - Land Processes Distributed Active Archive Center***\n",
    "\n",
    "The LP DAAC data is organised into:\n",
    "- folder directories per year-month \n",
    "- HDF files per sinusoidal grid unit\n",
    "\n",
    "To limit the number of requests we will obtain data for 1 month over the USA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params fo LP DAAC\n",
    "# you will require an EarthData login\n",
    "host = fr'https://e4ftl01.cr.usgs.gov/MOTA/MCD64A1.061'\n",
    "login = os.getenv('user')\n",
    "password = os.getenv('pwd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 folders found\n"
     ]
    }
   ],
   "source": [
    "# list folders \n",
    "r = requests.get(host, verify=True, stream=True,auth=(login,password))\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "folders = list()\n",
    "for link in soup.findAll('a', attrs={'href': re.compile(\"\\d{4}.\\d{2}.\\d{2}/\")}):\n",
    "    folders.append(link.get('href'))\n",
    "print(f\"{len(folders)} folders found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 files found in folder n\n"
     ]
    }
   ],
   "source": [
    "# list files in folder\n",
    "for f in folders[:1]:\n",
    "    file_list = list()\n",
    "    folder_url = f\"{host}/{f}\"\n",
    "    r = requests.get(folder_url, verify=True, stream=True,auth=(login,password))\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\".hdf$\")}):\n",
    "        file_list.append(link.get('href'))    \n",
    "print(f\"{len(file_list)} files found in folder n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This MODIS data product is delivered in the sinusoidal grid projection. We can apply regex to filter the query to just those tiles over the USA. Note how this projection warps the USA and other regions - we will need to account for this later.\n",
    "\n",
    "<img src=\"https://modis-land.gsfc.nasa.gov/images/MODIS_sinusoidal_grid1.gif\" width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 USA tiles found\n"
     ]
    }
   ],
   "source": [
    "# USA tiles only\n",
    "# use modis grid to slice only continents / areas of interest\n",
    "# https://modis-land.gsfc.nasa.gov/MODLAND_grid.html\n",
    "hreg = re.compile(\"h0[8-9]|h1[0-4]\")\n",
    "vreg = re.compile(\"v0[2-7]\")\n",
    "usa_files = list()\n",
    "for fl in file_list:\n",
    "    h = hreg.search(fl)\n",
    "    if h:\n",
    "        v = vreg.search(h.string)\n",
    "        if v:\n",
    "            usa_files.append(v.string)\n",
    "print(f\"{len(usa_files)} USA tiles found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCD64A1.A2000306.h08v03.061.2021085164213.hdf 1\n",
      "MCD64A1.A2000306.h08v04.061.2021085165152.hdf 2\n"
     ]
    }
   ],
   "source": [
    "# download file from folder\n",
    "# implement 25 file timeout to avoid rate limit\n",
    "\n",
    "exceptions = list()\n",
    "for f in folders[:1]:\n",
    "    for e,fl in enumerate(usa_files[:]):\n",
    "        if (e+1) % 10 == 0:\n",
    "            print('sleep')\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(fl,e+1)\n",
    "            try:\n",
    "                file_url = f\"{host}/{f}/{fl}\"\n",
    "                r = requests.get(file_url, verify=True, stream=True,auth=(login,password))\n",
    "                open(f'./data/raw/{fl}',\"wb\").write(r.content)\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                exceptions.append(fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MODIS HDF files and CRS***\n",
    "\n",
    "HDF files are self describing - this means that all elements (the file itself, groups and datasets) can have associated metadata that describes the information contained within the element. You can read more about HDF files in my [previous post on MODIS](https://bpostance.github.io/posts/working-with-MODIS-data/).\n",
    "\n",
    "<img src=\"https://www.earthdatascience.org/images/earth-analytics/hierarchical-data-formats/hdf5-example-data-structure-with-metadata.jpg\" width=\"200\" height=\"200\">\n",
    "\n",
    "The MODIS land products are produced at 4 resolutions (250m, 500m, 1km, and 0.05 degree), and in 3 projections (Sinusoidal, Lambert Azimuthal Equal-Area, and Geographic). The simple Geographic lat/lon projection is only used for the coarsest resolution grid, produced at 0.05 km (~ 5.5 km), which is referred to as the Climate Modeling Grid (CMG). In order to maintain reasonable file sizes for the other higher resolution MODIS land data products, each projection is divided up into a tiled grid. \n",
    "\n",
    "Geospatial data products have a coordinate reference system (CRS). The CRS refers to the way in which spatial data are represented over the earthâ€™s surface. Most people will be familiar with the WGS 84 (EPSG:4326) CRS as this is widely used in global mapping products like Google or Apple maps. There are many CRS that provide varying degrees of accuracy across the globe, CRS are chosen to suit the needs of the data analyis or application. See more on [CRS here](https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/)\n",
    "\n",
    "To work more efficiently with these data we will i) translate them to geotiff format which is essentially an array with spatial information, and ii) reproject the data to a common CRS. There are a number of methods and tools to peform these tasks including:\n",
    "- [MODIS GUI tools](https://modis.gsfc.nasa.gov/tools/) distributed wiht the data\n",
    "- Programming tools in Python and [R](https://www.jessesadler.com/post/gis-with-r-intro/)\n",
    "\n",
    "We want a programmatic method when working with large data and repetitive geospatial datasets. Below are two methods to convert MODIS data using python packages fro [GDAL](https://gdal.org/) and [Rasterio](https://rasterio.readthedocs.io/en/latest/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GDAL Warp***\n",
    "\n",
    "GDAL is a command line executable. The cmd to run on the terminal is:\n",
    "```\n",
    "!gdalwarp -of GTiff -t_srs \"EPSG:4326\" HDF4_EOS:EOS_GRID:\".\\MCD64A1.A2000306.h08v04.061.2021085165152.hdf\":MOD_Grid_Monthly_500m_DB_BA:\"Burn Date\" test.tif\n",
    "```\n",
    "\n",
    "and the python binding is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fl in usa_files[:]:       \n",
    "    in_file = f\"./data/raw/{fl}\"\n",
    "    out_file = f\"./data/transformed/{fl.replace('.hdf','.tif')}\"\n",
    "    \n",
    "    # open dataset\n",
    "    dataset = gdal.Open(in_file,gdal.GA_ReadOnly)\n",
    "    subdataset =  gdal.Open(dataset.GetSubDatasets()[0][0], gdal.GA_ReadOnly)\n",
    "    \n",
    "    # gdalwarp\n",
    "    kwargs = {'format': 'GTiff', 'dstSRS': 'EPSG:4326'}\n",
    "    ds = gdal.Warp(destNameOrDestDS=out_file,srcDSOrSrcDSTab=subdataset, **kwargs)\n",
    "    del ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the output from gdal into QGIS (or any visualisation tool) we see the transformed data in relation to WGS84 global shorlines, and we can see the warp (curve) effect at the tile boundaries. This warp is created from translating the MODIS tiles from native Sinusoidal tiles to WGS84 Mercator grid. But you can see how the blue (water), green (no burn) MODIS shaded area's lie within the shoreline data confirming that the translation was sucessfull. There are few burn areas (red) visible in this image as we are zoomed out in order to see the translation.\n",
    "\n",
    "<img src=\"./map.png\" width=\"600\" height=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Rasterio***\n",
    "\n",
    "Rasterio is a dedicated pyton package for geospatial data and analytics. The library provides more granular access and options to low level functions, at the expense of brevity. If you need to perform some bespoke transformations and operations, or want to optimise your pipeline for larger datasets, rasterio is a good option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "# for fl in [fl for fl in usa_files if fl == 'MCD64A1.A2000306.h08v04.061.2021085165152.hdf']:       \n",
    "\n",
    "#     file_name = f'./data/{fl}'\n",
    "\n",
    "#     all_bands = []\n",
    "\n",
    "#     with rio.open(file_name) as dataset:\n",
    "#         # capture meta and CRS data\n",
    "#         hdf4_meta = dataset.meta \n",
    "#         crs = dataset.read_crs()\n",
    "\n",
    "#         # iterate data layers and select using name\n",
    "#         for layer_name in dataset.subdatasets[:1]:\n",
    "#             #print(layer_name)\n",
    "#             with rio.open(layer_name) as subdataset:\n",
    "#                 bounds = subdataset.bounds\n",
    "#                 modis_meta = subdataset.profile\n",
    "#                 all_bands.append(subdataset.read(1))\n",
    "\n",
    "#         # prep metadata object\n",
    "#         output_meta = modis_meta.copy()\n",
    "#         output_meta['driver'] = 'GTiff'\n",
    "#         output_meta['count'] = 1 # all_bands[0].shape[0]\n",
    "        \n",
    "#         with rio.open(out_path, \"w\", **kwargs) as dest:\n",
    "#             dest.write(all_bands[0],indexes=1)\n",
    "        \n",
    "#         # reproject to 4326\n",
    "#         dst_crs = \"EPSG:4326\"\n",
    "#         transform, width, height = calculate_default_transform(output_meta.data['crs'],\n",
    "#                                                                dst_crs,\n",
    "#                                                                output_meta.data['width'],\n",
    "#                                                                output_meta.data['height'],\n",
    "#                                                                *bounds,\n",
    "#                                                                dst_width=output_meta.data['width'],\n",
    "#                                                                dst_height=output_meta.data['height'],)\n",
    "#         kwargs = modis_meta.copy()\n",
    "#         kwargs.update({'crs': dst_crs,\n",
    "#                        'transform': transform,\n",
    "#                        'width': width,\n",
    "#                        'height': height})\n",
    "\n",
    "#         # reproject and write to file e as a geotiff\n",
    "#         out_path = f'{fl}.tif'\n",
    "#         ino = all_bands[0]\n",
    "#         ooo = all_bands[0].copy()\n",
    "#         with rio.open(out_path, \"w\", **kwargs) as dest:\n",
    "#             reproject(source=ino,\n",
    "#                       destination=ooo,\n",
    "#                       src_transform=modis_meta.data['transform'],\n",
    "#                       src_crs=modis_meta.data['crs'],\n",
    "#                       dst_transform=transform,\n",
    "#                       dst_crs=dst_crs,\n",
    "#                       resampling=Resampling.nearest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [global shorlines](https://www.ngdc.noaa.gov/mgg/shorelines/data/gshhg/latest/)\n",
    "- [python Gdal](https://gdal.org/python/osgeo.gdal-module.html)\n",
    " - [read HDF in gdal](https://gis.stackexchange.com/questions/72178/how-to-extract-subdataset-from-hdf-raster/72196)\n",
    " - [gdal Warp documentation](https://gdal.org/python/osgeo.gdal-module.html#WarpOptions)\n",
    " - [how to use gdal Warp()](https://gis.stackexchange.com/a/341693/56176)\n",
    "- https://developers.google.com/earth-engine/datasets/catalog/JRC_GWIS_GlobFire_v2_FinalPerimeters#description\n",
    "- https://www.nature.com/articles/s41597-019-0312-2\n",
    "- https://lpdaac.usgs.gov/products/mcd64a1v061/\n",
    "- https://git.earthdata.nasa.gov/projects/LPDUR\n",
    "- https://hdfeos.org/forums/showthread.php?t=496\n",
    "- https://git.earthdata.nasa.gov/projects/LPDUR/repos/2020-agc-workshop/browse\n",
    "- https://modis.gsfc.nasa.gov/tools/\n",
    "- https://modis-land.gsfc.nasa.gov/MODLAND_grid.html\n",
    "- [Converting MODIS HDFs with sinusoidal projections to ArcGIS raster format](https://code.env.duke.edu/projects/mget/wiki/SinusoidalMODIS)\n",
    "- [Welcome to GDAL notesâ€™s documentation!](http://jgomezdans.github.io/gdal_notes/intro.html#obtaining-satellite-data)\n",
    "- [Official MODIS authentication Python and R scripts](https://lpdaac.usgs.gov/tools/data-prep-scripts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo]",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}